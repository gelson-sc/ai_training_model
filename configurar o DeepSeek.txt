O jeito mais fácil e integrado ao PyCharm é usar o Ollama como motor:
Instale o Ollama (ollama.com).
No terminal, baixe o modelo: ollama run deepseek-r1:8b (ele cabe inteiro nos 12GB da sua GPU).
Instale a biblioteca para o Python: pip install ollama.

o Ubuntu, a instalação do Ollama é extremamente simples e direta via terminal.
Como você tem uma GPU NVIDIA, o instalador do Ollama já tentará configurar os drivers CUDA
automaticamente para que a IA rode na sua placa de vídeo.
Siga estes passos:
1. Instalação do Binário do Ollama
Abra o seu terminal (pode ser o do PyCharm ou o do sistema) e execute:
``` bash
curl -fsSL https://ollama.com/install.sh | sh
```

2. Verificar se o Ollama está rodando
Após o comando terminar, o serviço do Ollama geralmente inicia sozinho. Você pode testar digitando:
``` bash
ollama --version
```

3. Baixar o DeepSeek (Modelo de 8 bilhões de parâmetros)
Como sua GPU tem 12GB de VRAM, esse modelo vai rodar com performance máxima. Execute:
``` bash
ollama run deepseek-r1:8b
```

Nota: Na primeira vez, ele vai baixar cerca de 4.8GB. Quando terminar, você já poderá conversar com ele direto no terminal. Digite /exit para sair do chat do terminal.
4. Instalar a biblioteca Python (dentro do seu projeto)
Você recebeu um erro No module named 'ollama'. Isso acontece porque a biblioteca Python ainda não está instalada no seu ambiente virtual. No terminal do PyCharm, execute:``` bash
pip install ollama
```

5. Ajuste no Código para evitar o np.int64


### Dica para Ubuntu + NVIDIA:
Se você quiser monitorar o uso da sua placa de vídeo enquanto o DeepSeek "pensa",
abra um segundo terminal e digite:
``` bash
watch -n 1 nvidia-smi
```
